{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(),'unlabeled_data')\n",
    "paths = glob.glob(data_path + '\\**\\*.png', recursive = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = '../data/tfrecords/train.tfrecords'\n",
    "#if (os.path.isdir(\"../data/tfrecords/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #img = img.astype(np.float32)\n",
    "    img = img.astype(np.uint8)\n",
    "    #np.uint8\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _floats_feature(value):\n",
    "    return tf.train.Feature(\n",
    "               float_list=tf.train.FloatList(value=value)\n",
    "           )\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "counter : 16194\n"
     ]
    }
   ],
   "source": [
    "#tf.io.TFRecordWriter\n",
    "counter = 0\n",
    "with tf.io.TFRecordWriter(output_file_path) as writer:\n",
    "        for index, value in enumerate(paths):\n",
    "            img = load_image(paths[index])\n",
    "            image_h = img.shape[0]\n",
    "            image_w = img.shape[1]\n",
    "            if (image_h != 50) | (image_w != 50):\n",
    "                continue\n",
    "            counter += 1\n",
    "            example = tf.train.Example(\n",
    "              features=tf.train.Features(\n",
    "                  #feature = get_feature(img)\n",
    "                  feature = {\n",
    "                      'height': _int64_feature(image_h),\n",
    "                      'width': _int64_feature(image_w),\n",
    "                      'image_raw': _bytes_feature(img.tostring())}\n",
    "            ))\n",
    "            writer.write(example.SerializeToString())\n",
    "            print('\\r{:.1%}'.format((index+1)/len(paths)), end='')\n",
    "print(\"\\ncounter :\", counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(),'stl10_binary')\n",
    "data_path = os.path.join(data_path,'unlabeled_X.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stl10_dataset(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "        print(\"everything : \", type(everything))\n",
    "        print(\"everything.shape : \", everything.shape)\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "        print(\"images.shape : \", images.shape)\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        print(\"images.shape : \", images.shape)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything :  <class 'numpy.ndarray'>\n",
      "everything.shape :  (2764800000,)\n",
      "images.shape :  (100000, 3, 96, 96)\n",
      "images.shape :  (100000, 96, 96, 3)\n",
      "(100000, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "images = read_stl10_dataset(data_path)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_DIR=\"../data/tfrecords/\"\n",
    "if not os.path.exists(TRAIN_DATASET_DIR):\n",
    "    os.mkdir(TRAIN_DATASET_DIR)\n",
    "    \n",
    "TRAIN_FILE = 'train.tfrecords'\n",
    "writer = tf.io.TFRecordWriter(os.path.join(TRAIN_DATASET_DIR,TRAIN_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfrecord_dataset(images, writer):\n",
    "\n",
    "    # create training tfrecord\n",
    "    read_imgs_counter = 0\n",
    "    for i, image in enumerate(images):\n",
    "            \n",
    "        read_imgs_counter += 1\n",
    "        image_h = image.shape[0]\n",
    "        image_w = image.shape[1]\n",
    "\n",
    "        img_raw = image.tostring()\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'height': _int64_feature(image_h),\n",
    "                'width': _int64_feature(image_w),\n",
    "                'image_raw': _bytes_feature(img_raw)}))\n",
    "\n",
    "        writer.write(example.SerializeToString())\n",
    "    \n",
    "    print(\"End of TfRecord. Total of image written:\", read_imgs_counter)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of TfRecord. Total of image written: 100000\n"
     ]
    }
   ],
   "source": [
    "create_tfrecord_dataset(images, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
